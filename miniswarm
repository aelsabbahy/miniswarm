#!/bin/bash

set -e


#############
# Global opts
#############
# Set this to any value to disable colors
MS_NOCOLOR=""
# Default docker-machine driver
export MACHINE_DRIVER=${MACHINE_DRIVER:-"virtualbox"}

###################
# Output formatting
###################
DEF_COLOR=""
GREEN=""
RED=""
if ! [[ ${MS_NOCOLOR:-""} ]]; then
  DEF_COLOR="\x1b[0m"
  GREEN="\x1b[32;01m"
  RED="\x1b[31;01m"
fi

info() {
  echo -e "${GREEN}INFO: ${*}${DEF_COLOR}"
}

err() {
  echo -e "${RED}ERROR: ${*}${DEF_COLOR}"
}

line_prefix() {
  sed -e "s/^/[$1] /"
}

##############
# Misc helpers
##############
# Keep running command until it succeeds or we timeout
wait_for_command() {
  local command="$1"
  local retry=${2:-60}
  local sleep_time=${3:-1}

  local tries=0
  while (( tries < retry ));do
    tries=$((tries+1))
    if eval "$command";then
      echo
      return 0
    fi
    echo -n '.'
    sleep "$sleep_time"
  done
  echo "TIMED OUT"
  return 1
}

# Generates enumerated names
# generate_names "foo" 5
# output: foo0 foo1 foo2 foo3 foo4
generate_names() {
  local name=$1
  local count=$2
  for ((i=0; i<count; i++)); do
    echo "${name}${i}"
  done
}

# Based on input, generate wanted and missing instance variables
set_wanted_instances() {
  wanted_managers=( $(generate_names 'ms-manager' "$num_managers") )
  wanted_workers=( $(generate_names 'ms-worker' "$num_workers") )

  missing_managers=( $(missing_instances "ms-manager" "${wanted_managers[@]}") )
  missing_workers=( $(missing_instances "ms-worker" "${wanted_workers[@]}") )
  missing_instances=( "${missing_managers[@]}" "${missing_workers[@]}" )

  extra_managers=( $(extra_instances "ms-manager" "${wanted_managers[@]}") )
  extra_workers=( $(extra_instances "ms-worker" "${wanted_workers[@]}") )
  extra_instances=( "${extra_managers[@]}" "${extra_workers[@]}" )
}

extra_instances() {
  local filter=$1
  local wanted_instances=( ${@:2} )
  got_instances=$(docker-machine ls -q | grep "$filter" | sort)
  comm -13 <(IFS=$'\n'; echo "${wanted_instances[*]}" | sort) <(echo -e "$got_instances" | sort)
}

missing_instances() {
  local filter=$1
  local wanted_instances=( ${@:2} )
  got_instances=$(docker-machine ls -q | grep "$filter" | sort)
  comm -23 <(IFS=$'\n'; echo "${wanted_instances[*]}" | sort) <(echo -e "$got_instances" | sort)
}

# Opens url in browser
open_url() {
  if [[ "$OSTYPE" == "darwin"* ]]; then
    open "$1"
  else
    xdg-open "$1"
  fi
}

pids=()
# Waits for multiple pids, checking their return code
wait_for_pids() {
  for pid in "${pids[@]}"; do
    wait "$pid"
  done
  pids=()
}

# Add the last pid to our wait queue
add_last_pid() {
  pids=( ${pids[@]} $! )
}

################
# Docker helpers
################
create_instance() {
  docker-machine create "$1" 2>&1 | line_prefix "$1"
}

# Create missing instances
create_instances() {
  #pids=()
  for i in "${missing_instances[@]}"; do
    # If boot2docker.iso doesn't exist, then run fist command serially otherwise we error
    if ! [[ -e ~/.docker/machine/cache/boot2docker.iso ]]; then
      create_instance "$i"
    else
      create_instance "$i" &
      add_last_pid
      #pids=( ${pids[@]} $! )
      # Stagger to avoid VirtualBox errors when too many machines are launched in parallel
      sleep 3
    fi
  done
  wait_for_pids
}

# Check if node in our cluster and in a ready state
node_in_cluster() {
  docker-machine ssh ms-manager0 docker node ls 2>/dev/null | grep -q "$1 *Ready"
}

# Drain and leave the cluster
leave_cluster() {
  if node_in_cluster "$1"; then
    info "Draining node: $1"
    docker-machine ssh ms-manager0 docker node update --availability drain "$1" | line_prefix "$1"
    # Give it a few sec to drain
    # FIXME: There's probably a better way to do this
    sleep 3
    info "Leaving cluster: $1"
    docker-machine ssh "$1" docker swarm leave --force 2>&1 | line_prefix "$1"
  fi
}

# Cause instance to leave cluster, and remove node from swarm
delete_from_cluster() {
  # First we leave
  leave_cluster "$1"
  # Use ids in-case there are multiple matches for a given name
  ids=$(docker-machine ssh ms-manager0 docker node ls -qf name="$1")
  for id in $ids; do
    # Wait for node to be in down state so we can remove from swarm cluster
    info "Waiting for node id=$id to be in a down state"
    wait_for_command "docker-machine ssh ms-manager0 docker node ls -f id=$id |grep -q Down"
    docker-machine ssh ms-manager0 docker node rm "$id" > /dev/null
  done
}

# Delete extra instances
# call with --force to skip leaving the cluster gracefully
delete_instances() {
  if [[ ${#extra_instances[@]} -eq 0 ]]; then
    return 0
  fi
  # Gracefully leave cluster
  if [[ ${1:-""} != "--force" ]]; then
    for i in "${extra_instances[@]}"; do
      delete_from_cluster "$i" &
      add_last_pid
    done
    wait_for_pids
  fi
  docker-machine rm -y "${extra_instances[@]}"
}

# Stop instances in our miniswarm cluster
stop_instances() {
  # Cluster gets out of wack when IP addresses change
  # remove workers
  for i in $(docker-machine ls -q | grep "ms-\(manager\|worker\)[0-9][0-9]*"); do
    [[ $i == "ms-manager0" ]] && continue
    {
      # if we don't do this raft consensus breaks
      if [[ $i == *manager* ]]; then
        info "Demoting instance: $i"
        docker-machine ssh ms-manager0 docker node demote "$i"
      fi
      info "Stopping instance: $i"
      delete_from_cluster "$i" | line_prefix "$i";
      docker-machine stop "$i" | line_prefix "$i";
    } &
    add_last_pid
  done
  wait_for_pids
  # Kill the leader
  leave_cluster "ms-manager0" | line_prefix "ms-manager0";
  docker-machine stop "ms-manager0" | line_prefix "ms-manager0";
}

# Start the instance and regenerate its certs to avoid cert issues when IP changes
start_instance() {
  info "Starting instance: $1"
  docker-machine start "$1"
  docker-machine regenerate-certs -f "$1"
  info "Waiting for instance name=$1 to be in a running state"
  wait_for_command "docker-machine ls --filter name=$1 --filter state=running -q | grep -q $1"
}

# Start all stopped instances that match our naming convention
start_instances() {
  to_start=( $(docker-machine ls -q --filter state=Stopped | grep "ms-\(worker\|manager\)[0-9][0-9]*" || true) )
  info "Starting: ${to_start[*]}"
  for i in "${to_start[@]}"; do
    start_instance "$i" | line_prefix "$i" &
    add_last_pid
  done
  wait_for_pids
}

# Silly check to see if our cluster is initialized
cluster_is_initialized() {
  docker-machine ssh ms-manager0 docker node ls > /dev/null 2>&1
}

# Initialize the cluster
init_cluster() {
  if ! cluster_is_initialized; then
    info "Initializing cluster"
    docker-machine ssh ms-manager0 docker swarm init \
      --advertise-addr "$manager_ip" --listen-addr "$manager_ip" > /dev/null
  fi
}

# Join the swarm cluster
join_cluster() {
  if ! node_in_cluster "$1"; then
    node_ip=$(docker-machine ip "$1")
    docker-machine ssh "$1" docker swarm leave --force 2> /dev/null | line_prefix "$1"
    docker-machine ssh "$1" docker swarm join "$manager_ip" --listen-addr "$node_ip" --token "$2" 2>&1 | line_prefix "$1"
  fi
}

# Get registration tokens
lookup_and_set_tokens() {
  manager_token=$(docker-machine ssh ms-manager0 docker swarm join-token -q manager)
  worker_token=$(docker-machine ssh ms-manager0 docker swarm join-token -q worker)
}

# Our main mainger ip
lookup_and_set_manager_ip() {
  manager_ip=$(docker-machine ip ms-manager0)
}

# Initialize cluster and add managers/workers
create_cluster() {
  lookup_and_set_manager_ip
  init_cluster
  lookup_and_set_tokens
  for i in "${wanted_managers[@]}"; do
      join_cluster "$i" "$manager_token" &
      add_last_pid
  done
  for i in "${wanted_workers[@]}"; do
      join_cluster "$i" "$worker_token" &
      add_last_pid
  done
  wait_for_pids
}

# Scale cluster to our desired size
scale_cluster() {
  set_wanted_instances
  [[ ${missing_instances[*]} ]] && info "Creating: ${missing_instances[*]}"
  [[ ${extra_instances[*]} ]] && info "Deleting: ${extra_instances[*]}"
  create_instances
  delete_instances
  start_instances
  create_cluster
}

# You shall not pass if you're not connected to a swarm
fail_if_not_connected_to_swarm() {
  if ! docker node ls > /dev/null 2>&1; then
    err "Not connected to a swarm cluster, please configure the environment and try again, example:"
    err 'eval $(docker-machine env MANAGER_NODE)'
    exit 1
  fi
  info "Connected to manager: $DOCKER_MACHINE_NAME"
}

# Deploy swarm visualizer, because it's awesome
deploy_swarm_visualizer() {
  fail_if_not_connected_to_swarm
  manager_ip=$(docker-machine ip "$DOCKER_MACHINE_NAME")
  (
  #eval "$(docker-machine env ms-manager0)"
  if [[ $(docker ps -qa -f 'Status=running' -f Name='swarm_visualizer') ]]; then
    return 0
  fi
  if [[ $(docker ps -qa -f 'Status=exited' -f Name='swarm_visualizer') ]]; then
    docker rm -vf swarm_visualizer > /dev/null
  fi
  docker run -it -d --name swarm_visualizer -p 5000:5000 -e HOST="$manager_ip" -e PORT=5000 -v /var/run/docker.sock:/var/run/docker.sock manomarks/visualizer
  )
  # Wait for it to come up
  wait_for_command "curl -s http://${manager_ip}:5000 -o /dev/null"
}

# Remove all services
remove_services() {
  info 'Removing deployed services'
  (
  eval "$(docker-machine env ms-manager0)"
  docker service rm $(docker service ls -q)
  )
}

##############
# CLI commands
##############
# FIXME: implement
print_help() {
  script_name=$(basename "$0")
  echo -e "Usage: $script_name COMMAND"
  echo -e "\nCluster management commands:"
  echo -e " start  - start miniswarm cluster"
  echo -e " stop   - stop miniswarm cluster"
  echo -e " scale  - scale miniswarm cluster"
  echo -e " delete - delete miniswarm cluster"
  echo -e "\nCluster helper commands:"
  echo -e " vis     - Start a cluster visualization GUI"
  echo -e " service - Open service url"
  echo -e " health  - View the health of a service"
  echo -e " logs    - View the logs of a service"
  echo -e "\nCommand Options/Examples:"
  echo -e "\nstart/scale Options:"
  echo -e "You can pass in either one or two arguments to configure the size of the cluster"
  echo -e "If one argument (N) is passed in, we launch 1 manager and N-1 workers"
  echo -e "\nExamples:"
  echo -e "# Create 1 manager and 2 workers"
  echo -e "$script_name start 3"
  echo -e "\n# Create 2 manager and 3 workers"
  echo -e "$script_name start 2 3"
  echo -e "\n# Scale cluster down to 1 manager and 1 worker"
  echo -e "$script_name scale 2"
  echo -e "\n# Start previously stopped cluster, or if there isn't one start a 1 manager cluster"
  echo -e "$script_name start"
  echo -e "\nhealth options:"
  echo -e "$script_name health SERVICE [-a]"
  echo -e "-a - Print health of all tasks of a service, including exited ones"
  echo -e "\nlogs options:"
  echo -e "$script_name logs SERVICE [-f]"
  echo -e "-f - Tail the logs of the service"
}

# Same as scale, but with connection instructions at the end
cmd_start() {
  info "Starting miniswarm"
  cmd_scale "$@"
  echo -e "\n\n"
  info "Stack starup complete. To connect to your stack, run the following command:"
  info 'eval $(docker-machine env ms-manager0)'
}

# Run the visualizer
cmd_vis() {
  deploy_swarm_visualizer
  url="http://${manager_ip}:5000"
  if [[ ${1:-""} == "--url" ]]; then
    echo "$url"
  else
    info "Launching browser with URL: $url"
    open_url "$url"
  fi
}

# Scale our swarm
cmd_scale() {
  info "Scaling miniswarm"
  case "$#" in
    0)
      # lookup what's already there
      num_managers=$(docker-machine ls -q | grep -c "ms-manager[0-9][0-9]*" || true)
      num_workers=$(docker-machine ls -q | grep -c "ms-worker[0-9][0-9]*" || true)
      if ((num_managers==0)) && ((num_workers==0)); then
        num_managers=1
        num_workers=0
      fi
    ;;
    1)
    num_managers=1
    num_workers=$((num_workers + $1 - num_managers))
      ;;
    2)
    num_managers=$1
    num_workers=$2
      ;;
    *)
      print_help
      exit 1
  esac
  scale_cluster
}

cmd_stop() {
  info "Stopping miniswarm"
  # FIXME: Stopping and starting a cluster causes services to hang
  # for now removing all services until this is fixed
  remove_services
  stop_instances
}

cmd_delete() {
  info "Deleting miniswarm"
  num_managers=0
  num_workers=0
  set_wanted_instances
  info "Deleting: ${extra_instances[*]}"
  delete_instances --force
}

cmd_service() {
  fail_if_not_connected_to_swarm
  manager_ip=$(docker-machine ip "$DOCKER_MACHINE_NAME")
  (
  #eval "$(docker-machine env ms-manager0)"
  port=$(docker service inspect --format '{{(index .Endpoint.Ports 0).PublishedPort}}' "$1")
  url="http://${manager_ip}:${port}"
  if [[ ${2:-""} == "--url" ]]; then
    echo "$url"
  else
    info "Launching browser with URL: $url"
    open_url "$url"
  fi
  )
}

# View healthchecks of service
cmd_health() {
  fail_if_not_connected_to_swarm
  while read line; do
    if [[ $2 != "-a" ]]; then
      grep -q 'Running' <<<$line || continue
    fi
    node=$(sed -e 's/^[^ ]*[ _]*[^ ]* [^ ]* *\([^ ]*\).*/\1/' <<<$line)
    name=$(sed -e 's/^[^ ]*[ _]*\([^ ]*\).*/\1/' <<<$line)
    id=$(sed -e 's/^\([^ ]*\).*/\1/' <<<$line)
    (
    # docker-machine ssh doesn't like the quotes in docker inspect -f
    eval "$(docker-machine env "$node")"
    docker inspect -f '{{ range .State.Health.Log }}{{ println "======\nStart:" .Start "\n======"}}{{ .Output }}{{end}}' "${name}.${id}" | line_prefix "${node} ${name}.${id}"
    )
  done < <(docker service ps "$1" | tail -n +2)
}

# View logs of service
cmd_logs() {
  fail_if_not_connected_to_swarm
  while read line; do
    node=$(sed -e 's/^[^ ]*[ _]*[^ ]* [^ ]* *\([^ ]*\).*/\1/' <<<$line)
    name=$(sed -e 's/^[^ ]*[ _]*\([^ ]*\).*/\1/' <<<$line)
    id=$(sed -e 's/^\([^ ]*\).*/\1/' <<<$line)
    [[ $2 == "-f" ]] && opts="-f"
    (
    # docker-machine ssh doesn't like the quotes in docker inspect -f
    eval "$(docker-machine env "$node")"
    docker logs $opts "${name}.${id}" 2>&1 | line_prefix "${node} ${name}.${id}"
    ) &
    add_last_pid
  done < <(docker service ps "$1" | tail -n +2)
  wait_for_pids
}

main() {
  case "$1" in
    start)
      cmd_start "${@:2}"
      ;;
    stop)
      cmd_stop
      ;;
    scale)
      cmd_scale "${@:2}"
      ;;
    delete)
      cmd_delete
      ;;
    vis|visualize|visualizer)
      cmd_vis "${@:2}"
      ;;
    service)
      cmd_service "${@:2}"
      ;;
    health)
      cmd_health "${@:2}"
      ;;
    logs)
      cmd_logs "${@:2}"
      ;;
    ""|help|-h)
      print_help
      ;;
    *)
      print_help
      echo -e "\n"
      err "Unknown command: $1"
      exit 1
      ;;
  esac
}

main "$@"
